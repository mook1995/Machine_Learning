{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9764324a-c62b-46dc-aa80-cf78ccf29da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, LeakyReLU\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df3b8699-4263-4aff-876f-57b218dd46d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "if not os.path.exists('./gan_images'):\n",
    "    os.makedirs('./gan_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a1d990c-d416-4590-8562-d2f9c54e869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Sequential()\n",
    "generator.add(Dense(128*7*7, input_dim=100, activation=LeakyReLU(0.2)))\n",
    "#1차원으로 늘어선 100픽셀의 노이즈를 만든다. \n",
    "#128*7*7은 7*7이미지 128장을 만든다는 것을 읽기 쉽도록 표현한것으로 저 계산값을 그대로 넣어줘도 된다.\n",
    "generator.add(BatchNormalization())\n",
    "#가중치 값들을 평균이 0 표준편차가 1을 갖는 상태로 만들어주는게 batch normalization 일종의 정규화 작업으로 \n",
    "#배치값들이 튀지 않게 해주는것이다. \n",
    "generator.add(Reshape((7,7,128)))\n",
    "#3차원 이미지로 리쉐입한다. \n",
    "generator.add(UpSampling2D())\n",
    "#UpSampling은 MaxPooling과는 반대의 개념으로 가로새로를 확장시키는것이다. \n",
    "generator.add(Conv2D(64, kernel_size=5, padding ='same'))\n",
    "generator.add(BatchNormalization())\n",
    "#batchnormalization을 이렇게 여러번 넣는것은 경험적으로 터득하게되는 결정이다. 이 쯤에 넣으면 최상이라는 것이다.\n",
    "generator.add(Activation(LeakyReLU(0.2)))\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(1, kernel_size=5, padding = 'same', activation='tanh'))\n",
    "#여기서 1개를 출력하는것은 어떤 이미지 하나를 만들어내겠다는것이다.\n",
    "\n",
    "#>>>> 이상이 generator를 만드는 방법이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3653e9a0-7316-4037-8756-5ee43f33ca92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 6272)              25088     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 14, 14, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 1)         1601      \n",
      "=================================================================\n",
      "Total params: 865,281\n",
      "Trainable params: 852,609\n",
      "Non-trainable params: 12,672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10a3531a-60f7-4de3-888a-c14ef0e2aea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Sequential()\n",
    "discriminator.add(Conv2D(64, kernel_size = 5, strides=2, input_shape=(28,28,1), padding='same'))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Conv2D(128, kernel_size = 5, strides=2, padding='same'))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c0beca7-880d-4f17-a6c8-525f9cfd1d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "discriminator.trainable = False\n",
    "#discriminator는 generator가 학습하는 동안에는 학습을 하면안되는데 진위판별 기준이 바뀌면 안되기 때문이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "703bb8c2-3eb2-4816-b6db-e82592dbc711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6273      \n",
      "=================================================================\n",
      "Total params: 212,865\n",
      "Trainable params: 0\n",
      "Non-trainable params: 212,865\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2e48c35-0588-4f77-b707-06f8301b9940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 28, 28, 1)         865281    \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1)                 212865    \n",
      "=================================================================\n",
      "Total params: 1,078,146\n",
      "Trainable params: 852,609\n",
      "Non-trainable params: 225,537\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#keras에서 제공하는 제너레이터와 디스크리미네이터를 합치는 방법\n",
    "ginput = Input(shape=(100,))\n",
    "dis_output = discriminator(generator(ginput))\n",
    "gan = Model(ginput, dis_output)\n",
    "gan.compile(loss='binary_crossentropy', optimizer = 'adam')\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f58607a9-691c-4477-995b-f5bb6287703c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (Temp/ipykernel_3148/2062630442.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\fplc8\\AppData\\Local\\Temp/ipykernel_3148/2062630442.py\"\u001b[1;36m, line \u001b[1;32m12\u001b[0m\n\u001b[1;33m    for i in range(epoch):\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def gan_train(epoch, batch_size, saving_interval):\n",
    "    (X_train, _), (_, _) = mnist.load_data()\n",
    "    #test데이터가 필요없는데 discriminator가 알아서 테스트하기 때문이다.\n",
    "    #마찬가지로 타겟값역시 discriminator의 것을 쓴다. \n",
    "    X_train = X_train.reshape(X_train.shape[0], 28,28,1).astype('float')\n",
    "    X_train = (X_train - 127.5)/ 127.5\n",
    "    #전체 픽셀 데이터를 -1에서 1사이로 마춘것이다. \n",
    "    \n",
    "    true = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        idx = np.random.randin(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, true)\n",
    "        #train_on_batch : 배치가 도는 순간 학습을 시키는 함수임 \n",
    "        #타겟은 전부 트루다라는 방식으로 학습을 시킵니다. \n",
    "        \n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "        #현재 가중치와 파라미터를 기준으로 결과를 추측해주는게 predict \n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "        #fake가 들어왔을 때의 손실값을 구한다. \n",
    "        \n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        #discriminator의 평균 손실을 구해본다. \n",
    "        \n",
    "        g_loss = gan.train_on_batch(noise, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106c90aa-0f92-4ab3-80ce-e7b708f8d2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
