{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d72a3b-933e-4380-9441-8b82980a3569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb715f34-cc7c-4c08-97d5-031e0841bb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string],'')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val' + string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d057576-7249-4217-a45b-d90b8d851d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data_in/'\n",
    "DATA_OUT_PATH = './data_out/'\n",
    "TRAIN_Q1_DATA_FILE = 'train_q1.npy'\n",
    "TRAIN_Q2_DATA_FILE = 'train_q2.npy'\n",
    "TRAIN_LABEL_DATA_FILE = 'train_label.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "096bc65f-4b12-42c1-a599-22bf3780a215",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_NUM = 1234\n",
    "tf.random.set_seed(SEED_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6736389-c39f-4be1-b4a2-511ccede61b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_data = np.load(open(DATA_IN_PATH + TRAIN_Q1_DATA_FILE, 'rb'))\n",
    "q2_data = np.load(open(DATA_IN_PATH + TRAIN_Q2_DATA_FILE, 'rb'))\n",
    "labels = np.load(open(DATA_IN_PATH + TRAIN_LABEL_DATA_FILE, 'rb'))\n",
    "prepro_configs = json.load(open(DATA_IN_PATH + DATA_CONFIGS, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0b6b569-57a1-477d-869b-fd96b3a20e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cnn_similarity'\n",
    "BATCH_SIZE = 1024\n",
    "NUM_EPOCHS = 100 \n",
    "VALID_SPLIT = 0.1\n",
    "MAX_LEN = 31\n",
    "\n",
    "kargs = {'model_name':model_name,\n",
    "        'vocab_size': prepro_configs['vocab_size'],\n",
    "        'word_embedding_dimension':100,\n",
    "        'conv_num_filters':300, \n",
    "        'conv_windows_size': 3,\n",
    "        'max_pool_seq_len': MAX_LEN, \n",
    "        'sent_embedding_dimension': 128,\n",
    "        'dropout_rate':0.2, \n",
    "        'hidden_dimension':200,\n",
    "        'output_dimension': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2364ac52-c11e-4f45-ac35-f89a6b35f917",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceEmbedding(layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(SentenceEmbedding, self).__init__()\n",
    "        \n",
    "        self.conv = layers.Conv1D(kargs['conv_num_filters'],\n",
    "                                 kargs['conv_windows_size'],\n",
    "                                 activation='relu',\n",
    "                                 padding='same')\n",
    "        self.max_pool = layers.MaxPool1D(kargs['max_pool_seq_len'], 1)\n",
    "        self.dense = layers.Dense(kargs['sent_embedding_dimension'], activation ='relu')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.dense(x)\n",
    "        \n",
    "        return tf.squeeze(x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba981d3c-75f4-4578-a991-7a30a1122e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceSimilarityModel(tf.keras.Model):\n",
    "    def __init__(self, **kargs):\n",
    "        super(SentenceSimilarityModel, self).__init__(name=kargs['model_name'])\n",
    "        self.word_embedding = layers.Embedding(kargs['vocab_size'] + 1, \n",
    "                                              kargs['word_embedding_dimension'])\n",
    "        self.base_encoder = SentenceEmbedding(**kargs)\n",
    "        self.hypo_encoder = SentenceEmbedding(**kargs)\n",
    "        self.dense = layers.Dense(kargs['hidden_dimension'], activation='relu')\n",
    "        self.logit = layers.Dense(kargs['output_dimension'], activation='sigmoid')\n",
    "        self.dropout = layers.Dropout(kargs['dropout_rate'])\n",
    "        \n",
    "    def call(self, x):\n",
    "        x1, x2 = x \n",
    "        b_x = self.word_embedding(x1)\n",
    "        h_x = self.word_embedding(x2)\n",
    "        b_x = self.dropout(b_x)\n",
    "        h_x = self.dropout(h_x)\n",
    "        \n",
    "        b_x = self.base_encoder(b_x)\n",
    "        h_x = self.base_encoder(h_x)\n",
    "        \n",
    "        e_x = tf.concat([b_x, h_x], -1)\n",
    "        e_x = self.dense(e_x)\n",
    "        e_x = self.dropout(e_x)\n",
    "        \n",
    "        return self.logit(e_x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c091749-2ba6-4a45-a167-0ac8106e277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceSimilarityModel(**kargs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "             loss =tf.keras.losses.BinaryCrossentropy(), \n",
    "             metrics = [tf.keras.metrics.BinaryAccuracy(name='accuracy')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8cfba81-3d8a-4cd9-8012-8145cf23f7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_out/cnn_similarity-- Folder create complete \n",
      "\n"
     ]
    }
   ],
   "source": [
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience = 3)\n",
    "\n",
    "checkpoint_path = DATA_OUT_PATH + model_name + '/weights.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print('{}-- Folder already exists \\n'.format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print('{}-- Folder create complete \\n'.format(checkpoint_dir))\n",
    "    \n",
    "cp_callback = ModelCheckpoint(checkpoint_path, monitor= 'val_accuracy', verbose =1,\n",
    "                             save_best_only=True, save_weigts_only =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0332dfd-c32c-4110-a3f0-6eaa70b9d521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "263/263 [==============================] - ETA: 0s - loss: 0.5479 - accuracy: 0.7194\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.69852, saving model to ./data_out/cnn_similarity\\weights.h5\n",
      "263/263 [==============================] - 97s 369ms/step - loss: 0.5479 - accuracy: 0.7194 - val_loss: 0.5381 - val_accuracy: 0.6985\n",
      "Epoch 2/100\n",
      "263/263 [==============================] - ETA: 0s - loss: 0.4393 - accuracy: 0.7945\n",
      "Epoch 00002: val_accuracy improved from 0.69852 to 0.75322, saving model to ./data_out/cnn_similarity\\weights.h5\n",
      "263/263 [==============================] - 96s 364ms/step - loss: 0.4393 - accuracy: 0.7945 - val_loss: 0.4768 - val_accuracy: 0.7532\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - ETA: 0s - loss: 0.3512 - accuracy: 0.8422\n",
      "Epoch 00003: val_accuracy improved from 0.75322 to 0.77500, saving model to ./data_out/cnn_similarity\\weights.h5\n",
      "263/263 [==============================] - 99s 376ms/step - loss: 0.3512 - accuracy: 0.8422 - val_loss: 0.4821 - val_accuracy: 0.7750\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - ETA: 0s - loss: 0.2717 - accuracy: 0.8825\n",
      "Epoch 00004: val_accuracy improved from 0.77500 to 0.78883, saving model to ./data_out/cnn_similarity\\weights.h5\n",
      "263/263 [==============================] - 97s 367ms/step - loss: 0.2717 - accuracy: 0.8825 - val_loss: 0.5416 - val_accuracy: 0.7888\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - ETA: 0s - loss: 0.2169 - accuracy: 0.9081\n",
      "Epoch 00005: val_accuracy improved from 0.78883 to 0.80203, saving model to ./data_out/cnn_similarity\\weights.h5\n",
      "263/263 [==============================] - 96s 365ms/step - loss: 0.2169 - accuracy: 0.9081 - val_loss: 0.5598 - val_accuracy: 0.8020\n",
      "Epoch 6/100\n",
      "263/263 [==============================] - ETA: 0s - loss: 0.1832 - accuracy: 0.9237\n",
      "Epoch 00006: val_accuracy improved from 0.80203 to 0.83596, saving model to ./data_out/cnn_similarity\\weights.h5\n",
      "263/263 [==============================] - 96s 365ms/step - loss: 0.1832 - accuracy: 0.9237 - val_loss: 0.5149 - val_accuracy: 0.8360\n",
      "Epoch 7/100\n",
      "263/263 [==============================] - ETA: 0s - loss: 0.1578 - accuracy: 0.9352\n",
      "Epoch 00007: val_accuracy did not improve from 0.83596\n",
      "263/263 [==============================] - 99s 377ms/step - loss: 0.1578 - accuracy: 0.9352 - val_loss: 0.8234 - val_accuracy: 0.7824\n",
      "Epoch 8/100\n",
      "263/263 [==============================] - ETA: 0s - loss: 0.1427 - accuracy: 0.9418\n",
      "Epoch 00008: val_accuracy did not improve from 0.83596\n",
      "263/263 [==============================] - 109s 414ms/step - loss: 0.1427 - accuracy: 0.9418 - val_loss: 0.8064 - val_accuracy: 0.7736\n",
      "Epoch 9/100\n",
      "263/263 [==============================] - ETA: 0s - loss: 0.1264 - accuracy: 0.9493\n",
      "Epoch 00009: val_accuracy did not improve from 0.83596\n",
      "263/263 [==============================] - 97s 369ms/step - loss: 0.1264 - accuracy: 0.9493 - val_loss: 0.6694 - val_accuracy: 0.8318\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((q1_data, q2_data), labels, batch_size = BATCH_SIZE, \n",
    "                   epochs = NUM_EPOCHS, validation_split = VALID_SPLIT, \n",
    "                   callbacks = [earlystop_callback, cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429364d6-cad6-4e19-a549-9976fa2a76a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
